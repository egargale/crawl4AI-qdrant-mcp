{"url": "https://docs.firecrawl.dev", "title": "Welcome to Firecrawl", "summary": "Firecrawl is an API service that takes a URL, crawls it, and converts it into clean markdown. It supports scraping, crawling, searching, and extracting structured data from websites.", "main_content": "{'title': 'Welcome to Firecrawl', 'summary': 'Firecrawl is an API service that takes a URL, crawls it, and converts it into clean markdown. It supports scraping, crawling, searching, and extracting structured data from websites.', 'main_content': 'Firecrawl is an API service that takes a URL, crawls it, and converts it into clean markdown. We crawl all accessible subpages and give you clean markdown for each. No sitemap required.', 'key_points': ['Firecrawl converts websites into LLM-ready data formats like markdown, HTML, and structured JSON.', 'It supports scraping, crawling, searching, and extracting structured data from websites.', 'Firecrawl provides SDKs for Python, Node.js, Go, Rust, and more.', 'It offers features like JSON mode for structured data extraction and actions to interact with web pages dynamically.'], 'metadata': {'url': 'https://docs.firecrawl.dev'}}", "key_points": ["Firecrawl converts websites into LLM-ready data formats like markdown, HTML, and structured JSON.", "It supports scraping, crawling, searching, and extracting structured data from websites.", "Firecrawl provides SDKs for Python, Node.js, Go, Rust, and more.", "It offers features like JSON mode for structured data extraction and actions to interact with web pages dynamically."], "metadata": {"url": "https://docs.firecrawl.dev"}}
{"url": "https://docs.firecrawl.dev", "title": "How to Use Firecrawl", "summary": "To use Firecrawl, sign up for an API key and use the provided SDKs or direct API calls to scrape, crawl, search, or extract data from websites.", "main_content": "{'title': 'How to Use Firecrawl', 'summary': 'To use Firecrawl, sign up for an API key and use the provided SDKs or direct API calls to scrape, crawl, search, or extract data from websites.', 'main_content': 'We provide an easy to use API with our hosted version. You can find the playground and documentation here. You can also self host the backend if you\u2019d like.', 'key_points': ['Sign up on Firecrawl to get an API key.', 'Use SDKs for Python, Node.js, Go, Rust, etc., or make direct API calls.', 'Firecrawl supports both hosted and self-hosted deployment options.'], 'metadata': {'url': 'https://docs.firecrawl.dev'}}", "key_points": ["Sign up on Firecrawl to get an API key.", "Use SDKs for Python, Node.js, Go, Rust, etc., or make direct API calls.", "Firecrawl supports both hosted and self-hosted deployment options."], "metadata": {"url": "https://docs.firecrawl.dev"}}
{"url": "https://docs.firecrawl.dev", "title": "Features of Firecrawl", "summary": "Firecrawl offers multiple features including scraping, crawling, mapping, searching, and extracting structured data from websites.", "main_content": "{'title': 'Features of Firecrawl', 'summary': 'Firecrawl offers multiple features including scraping, crawling, mapping, searching, and extracting structured data from websites.', 'main_content': 'Features include: Scrape (get content in LLM-ready format), Crawl (scrape all URLs of a website), Map (get all website URLs), Search (search the web and get full content), and Extract (get structured data from single or multiple pages).', 'key_points': ['Scrape: Get content in markdown, HTML, summary, or structured JSON.', 'Crawl: Automatically discover and extract content from a URL and its subpages.', 'Map: Get all URLs of a website quickly.', 'Search: Search the web and optionally scrape results.', 'Extract: Get structured data from pages using AI.'], 'metadata': {'url': 'https://docs.firecrawl.dev'}}", "key_points": ["Scrape: Get content in markdown, HTML, summary, or structured JSON.", "Crawl: Automatically discover and extract content from a URL and its subpages.", "Map: Get all URLs of a website quickly.", "Search: Search the web and optionally scrape results.", "Extract: Get structured data from pages using AI."], "metadata": {"url": "https://docs.firecrawl.dev"}}
{"url": "https://docs.firecrawl.dev", "title": "Powerful Capabilities", "summary": "Firecrawl handles complex tasks such as dynamic content rendering, anti-bot mechanisms, and media parsing, while providing fast and reliable results.", "main_content": "{'title': 'Powerful Capabilities', 'summary': 'Firecrawl handles complex tasks such as dynamic content rendering, anti-bot mechanisms, and media parsing, while providing fast and reliable results.', 'main_content': 'Firecrawl handles proxies, anti-bot mechanisms, dynamic content (JS-rendered), output parsing, orchestration, media parsing (PDFs, DOCX, images), and provides lightning-fast performance.', 'key_points': ['Supports dynamic content rendering and JS-driven websites.', 'Handles anti-bot mechanisms and proxies.', 'Parses media files like PDFs, DOCX, and images.', 'Delivers results in seconds for high-throughput use cases.', 'Offers customizability for crawling behind auth walls, excluding tags, and setting crawl depth.'], 'metadata': {'url': 'https://docs.firecrawl.dev'}}", "key_points": ["Supports dynamic content rendering and JS-driven websites.", "Handles anti-bot mechanisms and proxies.", "Parses media files like PDFs, DOCX, and images.", "Delivers results in seconds for high-throughput use cases.", "Offers customizability for crawling behind auth walls, excluding tags, and setting crawl depth."], "metadata": {"url": "https://docs.firecrawl.dev"}}
{"url": "https://docs.firecrawl.dev", "title": "Installing Firecrawl", "summary": "Firecrawl can be installed via pip for Python or npm for Node.js, and used with various SDKs and frameworks.", "main_content": "{'title': 'Installing Firecrawl', 'summary': 'Firecrawl can be installed via pip for Python or npm for Node.js, and used with various SDKs and frameworks.', 'main_content': \"Python: pip install firecrawl-py; Node: import Firecrawl from 'firecrawl'; SDKs available for Python, Node, Go, Rust, and others.\", 'key_points': ['Install via pip for Python: `pip install firecrawl-py`.', \"Node.js: Import Firecrawl from 'firecrawl'.\", 'SDKs are available for multiple languages including Python, Node.js, Go, and Rust.'], 'metadata': {'url': 'https://docs.firecrawl.dev'}}", "key_points": ["Install via pip for Python: `pip install firecrawl-py`.", "Node.js: Import Firecrawl from 'firecrawl'.", "SDKs are available for multiple languages including Python, Node.js, Go, and Rust."], "metadata": {"url": "https://docs.firecrawl.dev"}}
{"url": "https://docs.firecrawl.dev", "title": "Scraping with Firecrawl", "summary": "The `scrape` method allows you to extract content from a single URL in various formats like markdown, HTML, and structured JSON.", "main_content": "{'title': 'Scraping with Firecrawl', 'summary': 'The `scrape` method allows you to extract content from a single URL in various formats like markdown, HTML, and structured JSON.', 'main_content': 'To scrape a single URL, use the `scrape` method. It takes the URL as a parameter and returns the scraped data as a dictionary.', 'key_points': ['Use the `scrape` method to extract content from a single URL.', 'Supported formats include markdown, HTML, summary, and JSON.', 'Example code shows how to call the `scrape` function with a URL and desired formats.'], 'metadata': {'url': 'https://docs.firecrawl.dev'}}", "key_points": ["Use the `scrape` method to extract content from a single URL.", "Supported formats include markdown, HTML, summary, and JSON.", "Example code shows how to call the `scrape` function with a URL and desired formats."], "metadata": {"url": "https://docs.firecrawl.dev"}}
{"url": "https://docs.firecrawl.dev", "title": "Crawling with Firecrawl", "summary": "The `crawl` method allows you to automatically discover and extract content from a URL and all of its accessible subpages.", "main_content": "{'title': 'Crawling with Firecrawl', 'summary': 'The `crawl` method allows you to automatically discover and extract content from a URL and all of its accessible subpages.', 'main_content': 'The crawl feature allows you to automatically discover and extract content from a URL and all of its accessible subpages. With our SDKs, simply call the crawl method\u2014this will submit a crawl job, wait for it to finish, and return the complete results for the entire site.', 'key_points': ['Use the `crawl` method to scrape all accessible subpages of a URL.', 'Returns the complete results for the entire site after the crawl completes.', 'For large crawls, a `next` URL is provided to retrieve additional data in chunks.'], 'metadata': {'url': 'https://docs.firecrawl.dev'}}", "key_points": ["Use the `crawl` method to scrape all accessible subpages of a URL.", "Returns the complete results for the entire site after the crawl completes.", "For large crawls, a `next` URL is provided to retrieve additional data in chunks."], "metadata": {"url": "https://docs.firecrawl.dev"}}
{"url": "https://docs.firecrawl.dev", "title": "JSON Mode for Structured Data", "summary": "Firecrawl supports JSON mode for structured data extraction using Pydantic schemas.", "main_content": "{'title': 'JSON Mode for Structured Data', 'summary': 'Firecrawl supports JSON mode for structured data extraction using Pydantic schemas.', 'main_content': 'With JSON mode, you can easily extract structured data from any URL. We support pydantic schemas to make it easier for you too.', 'key_points': ['Use JSON mode to extract structured data from a URL.', 'Supports Pydantic schemas for defining the structure of the extracted data.', 'Example shows how to define a schema and use it with the `scrape` method.'], 'metadata': {'url': 'https://docs.firecrawl.dev'}}", "key_points": ["Use JSON mode to extract structured data from a URL.", "Supports Pydantic schemas for defining the structure of the extracted data.", "Example shows how to define a schema and use it with the `scrape` method."], "metadata": {"url": "https://docs.firecrawl.dev"}}
{"url": "https://docs.firecrawl.dev", "title": "Search with Firecrawl", "summary": "Firecrawl's search API allows you to perform web searches and optionally scrape the search results in one operation.", "main_content": "{'title': 'Search with Firecrawl', 'summary': \"Firecrawl's search API allows you to perform web searches and optionally scrape the search results in one operation.\", 'main_content': 'Firecrawl\u2019s search API allows you to perform web searches and optionally scrape the search results in one operation. Choose specific output formats (markdown, HTML, links, screenshots) and sources (web, news, images).', 'key_points': ['Use the `search` method to perform web searches.', 'Optionally scrape the search results directly.', 'Supports different sources like web, news, and images.'], 'metadata': {'url': 'https://docs.firecrawl.dev'}}", "key_points": ["Use the `search` method to perform web searches.", "Optionally scrape the search results directly.", "Supports different sources like web, news, and images."], "metadata": {"url": "https://docs.firecrawl.dev"}}
{"url": "https://docs.firecrawl.dev", "title": "Extracting Without Schema", "summary": "You can extract data without a schema by passing a prompt to the endpoint, allowing the LLM to determine the structure.", "main_content": "{'title': 'Extracting Without Schema', 'summary': 'You can extract data without a schema by passing a prompt to the endpoint, allowing the LLM to determine the structure.', 'main_content': 'You can now extract without a schema by just passing a `prompt` to the endpoint. The llm chooses the structure of the data.', 'key_points': ['Extract data without a predefined schema by passing a prompt.', 'The LLM determines the structure of the extracted data based on the prompt.', 'Example shows how to pass a prompt to extract the company mission from a page.'], 'metadata': {'url': 'https://docs.firecrawl.dev'}}", "key_points": ["Extract data without a predefined schema by passing a prompt.", "The LLM determines the structure of the extracted data based on the prompt.", "Example shows how to pass a prompt to extract the company mission from a page."], "metadata": {"url": "https://docs.firecrawl.dev"}}
{"url": "https://docs.firecrawl.dev", "title": "Interacting with Pages Using Actions", "summary": "Firecrawl allows you to perform actions like clicking, scrolling, and inputting text before scraping content, useful for dynamic content.", "main_content": "{'title': 'Interacting with Pages Using Actions', 'summary': 'Firecrawl allows you to perform actions like clicking, scrolling, and inputting text before scraping content, useful for dynamic content.', 'main_content': 'Firecrawl allows you to perform various actions on a web page before scraping its content. This is particularly useful for interacting with dynamic content, navigating through pages, or accessing content that requires user interaction.', 'key_points': ['Perform actions like click, scroll, input, and wait before scraping.', 'Use `wait` to ensure the page has loaded before executing other actions.', 'Example shows how to navigate to a login page, enter credentials, and take a screenshot.'], 'metadata': {'url': 'https://docs.firecrawl.dev'}}", "key_points": ["Perform actions like click, scroll, input, and wait before scraping.", "Use `wait` to ensure the page has loaded before executing other actions.", "Example shows how to navigate to a login page, enter credentials, and take a screenshot."], "metadata": {"url": "https://docs.firecrawl.dev"}}
